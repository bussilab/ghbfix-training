{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc8d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook prepares blocks for CVTrajectory in order to reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb6a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bussilab\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "import cudamat as cm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import concurrent.futures\n",
    "kBT=0.6 #kBT in kcal/mol\n",
    "np.random.seed(1995)\n",
    "import os\n",
    "curr_dir=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9243e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_simulation_data(files):\n",
    "    result=None\n",
    "    for t in files:\n",
    "        if result is None:\n",
    "            result=np.load(t)\n",
    "            output=+result\n",
    "        else:\n",
    "            result=np.load(t)\n",
    "            output=np.concatenate((output,result))\n",
    "\n",
    "    return output\n",
    "\n",
    "def read_TLs(files):\n",
    "    corr=[]\n",
    "    for file in files:\n",
    "        with open(file, \"r\") as f:\n",
    "            for line in f:\n",
    "                nums=line.split()\n",
    "                if nums:\n",
    "                    corr.append(np.array([float(i) for i in nums]))\n",
    "    return np.array(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9922943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_TL_bias(Sequence,key,prune,skip,trajGAGA,FFprefactorsGAGA,trajUUCG,FFprefactorsUUCG):\n",
    "    \n",
    "    directories=[\"nh-n_0.5_nh-o_0.5_oh-bo-nbO_-0.5_dumping\", \n",
    "                 \"nh-n_1.0_nh-o_0.0_oh-bo-nbO_-0.5_dumping_bias-from-half-half\",\n",
    "                 \"nh-n_0.5_nh-o_0.5_oh-bo-nbO_-0.5_dumping_bias-from-one-zero\",\n",
    "                 \"nh-n_1.0_nh-o_0.0_oh-bo-nbO_-0.5_dumping\"\n",
    "                 ]\n",
    "\n",
    "    collection_weights=[]\n",
    "    for index,d in enumerate(directories):\n",
    "        Metadweight=[]\n",
    "        with open(\"./data_loaded/%s/%s/weights.rep0\" %(Sequence,d) ,\"r\") as fp:\n",
    "            for line in fp:\n",
    "                Metadweight.append(float(line))\n",
    "        collection_weights.append(np.array(Metadweight))\n",
    "\n",
    "    MetadPot1=np.concatenate((collection_weights[0],collection_weights[1]))\n",
    "    MetadPot2=np.concatenate((collection_weights[2],collection_weights[3]))\n",
    "\n",
    "    MetadPot=np.c_[ MetadPot1,MetadPot2 ] \n",
    "    MetadPot=kBT*np.log(MetadPot)\n",
    "    \n",
    "    if prune==True:\n",
    "        MetadPot=MetadPot[::skip,:]\n",
    "    \n",
    "    if Sequence=='GAGA':\n",
    "        if key == 'reference':\n",
    "            bias=np.matmul(trajGAGA,np.array(FFprefactorsGAGA).T)+MetadPot\n",
    "        if key == 'proposed':\n",
    "            bias=np.matmul(trajGAGA,(FFprefactorsGAGA-FFprefactorsGAGA[1]).T)+MetadPot\n",
    "        \n",
    "    if Sequence=='UUCG':\n",
    "        if key == 'reference':\n",
    "            bias=np.matmul(trajUUCG,np.array(FFprefactorsUUCG).T)+MetadPot\n",
    "        if key == 'proposed':\n",
    "            bias=np.matmul(trajUUCG,(FFprefactorsUUCG-FFprefactorsUUCG[1]).T)+MetadPot\n",
    "        \n",
    "\n",
    "    del MetadPot1\n",
    "    del MetadPot2\n",
    "    del MetadPot\n",
    "        \n",
    "    return bias   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c350f7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 simulations per TL.\n",
      "Check shape of arrays:\n",
      "(1400000, 12)\n",
      "(1400000, 8)\n",
      "(1400000, 9)\n",
      "(1400000, 12)\n",
      "(1400000, 20)\n",
      "(1400000, 285)\n",
      "(1000000, 1)\n",
      "(1000000, 1)\n",
      "(1000000, 12)\n",
      "(1000000, 12)\n"
     ]
    }
   ],
   "source": [
    "#get the names of the different simulations and there forcefield prefactors\n",
    "trajectoryNamesGACC=[]\n",
    "trajectoryNamesGAGA=[]\n",
    "trajectoryNamesUUCG=[]\n",
    "FFprefactorsGACC=[]\n",
    "FFprefactorsGAGA=[]\n",
    "FFprefactorsUUCG=[]\n",
    "\n",
    "with open(\"./data_loaded/coefficients.dat\",\"r\") as fp:\n",
    "    for line in fp:\n",
    "        if(line[0]=='#'):\n",
    "            continue\n",
    "        l=line.split()\n",
    "        file=l[0]+\".skip.npy\"\n",
    "        trajectoryNamesGACC.append(file)\n",
    "        FFprefactorsGACC.append(np.array(np.array(l)[1:],dtype='float'))\n",
    "\n",
    "with open(\"./data_loaded/coefficients_TLs.dat\",\"r\") as fp:\n",
    "    for line in fp:\n",
    "        if(line[0]=='#'):\n",
    "            continue\n",
    "        if line.strip():\n",
    "            l=line.split()\n",
    "            file=l[0]+\".npy\"\n",
    "            if 'gaga' in line:\n",
    "                FFprefactorsGAGA.append(np.array(l[1:],dtype='float'))\n",
    "            if 'uucg' in line:\n",
    "                FFprefactorsUUCG.append(np.array(l[1:],dtype='float'))\n",
    "\n",
    "firstFF='nh-n_0.5_nh-o_0.5_oh-bo-nbO_-0.5_dumping/'\n",
    "secondFF='nh-n_1.0_nh-o_0.0_oh-bo-nbO_-0.5_dumping/'\n",
    "trajectoryNamesGAGA.append('./data_loaded/GAGA/'+firstFF+'gHBfix-parameters_state.rep0')\n",
    "trajectoryNamesGAGA.append('./data_loaded/GAGA/'+secondFF+'gHBfix-parameters_state.rep0')\n",
    "trajectoryNamesUUCG.append('./data_loaded/UUCG/'+firstFF+'gHBfix-parameters_state.rep0')\n",
    "trajectoryNamesUUCG.append('./data_loaded/UUCG/'+secondFF+'gHBfix-parameters_state.rep0')\n",
    "    \n",
    "trajGACC=concatenate_simulation_data(['./data_loaded/GACC/' + x for x in trajectoryNamesGACC])\n",
    "backbone1=concatenate_simulation_data(['./data_loaded/GACC/' + re.sub(\"HBfix-energy\",\"jcop_backbone-1\",x) for x in trajectoryNamesGACC])\n",
    "backbone2=concatenate_simulation_data(['./data_loaded/GACC/' + re.sub(\"HBfix-energy\",\"jcop_backbone-2\",x) for x in trajectoryNamesGACC])\n",
    "sugar=concatenate_simulation_data(['./data_loaded/GACC/' + re.sub(\"HBfix-energy\",\"jcop_sugar\",x) for x in trajectoryNamesGACC])\n",
    "noe=concatenate_simulation_data(['./data_loaded/GACC/' + re.sub(\"HBfix-energy\",\"noe\",x) for x in trajectoryNamesGACC])\n",
    "unoe=concatenate_simulation_data(['./data_loaded/GACC/' + re.sub(\"HBfix-energy\",\"unoe\",x) for x in trajectoryNamesGACC])\n",
    "\n",
    "#apply forward models\n",
    "sugar=9.67*np.cos(sugar*np.pi/180)**2 - 2.03*np.cos(sugar*np.pi/180)\n",
    "backbone1=9.7*np.cos(backbone1*np.pi/180)**2 - 1.8*np.cos(backbone1*np.pi/180)\n",
    "backbone2=15.3*np.cos(backbone2*np.pi/180)**2 - 6.1*np.cos(backbone2*np.pi/180)+1.6\n",
    "noe=noe**-6\n",
    "unoe=unoe**-6\n",
    "print('There are 2 simulations per TL.')\n",
    "trajGAGA=read_TLs([x for x in trajectoryNamesGAGA])\n",
    "trajUUCG=read_TLs([x for x in trajectoryNamesUUCG])\n",
    "populationGAGA=trajGAGA[:,-1].reshape(-1,1)\n",
    "populationUUCG=trajUUCG[:,-1].reshape(-1,1)\n",
    "trajGAGA=trajGAGA[:,:12]\n",
    "trajUUCG=trajUUCG[:,:12]\n",
    "\n",
    "#to obtain the same parameters as published set prune=False\n",
    "prune=False\n",
    "if prune==True:\n",
    "    skip=5000\n",
    "    print(\"Pruning data, skip\")\n",
    "    trajGACC=trajGACC[::skip,:]\n",
    "    backbone1=backbone1[::skip,:]\n",
    "    backbone2=backbone2[::skip,:]\n",
    "    sugar=sugar[::skip,:]\n",
    "    noe=noe[::skip,:]\n",
    "    unoe=unoe[::skip,:]\n",
    "    populationGAGA=populationGAGA[::skip,:]\n",
    "    populationUUCG=populationUUCG[::skip,:]\n",
    "    trajGAGA=trajGAGA[::skip,:]\n",
    "    trajUUCG=trajUUCG[::skip,:]\n",
    "else:\n",
    "    skip=0\n",
    "\n",
    "print(\"Check shape of arrays:\")\n",
    "print(trajGACC.shape)\n",
    "print(backbone1.shape)\n",
    "print(backbone2.shape)\n",
    "print(sugar.shape)\n",
    "print(noe.shape)\n",
    "print(unoe.shape)\n",
    "print(populationGAGA.shape)\n",
    "print(populationUUCG.shape)\n",
    "print(trajGAGA.shape)\n",
    "print(trajUUCG.shape)\n",
    "\n",
    "biasGAGA=calculate_TL_bias('GAGA','proposed',prune,skip,trajGAGA,FFprefactorsGAGA,trajUUCG,FFprefactorsUUCG)\n",
    "biasUUCG=calculate_TL_bias('UUCG','proposed',prune,skip,trajGAGA,FFprefactorsGAGA,trajUUCG,FFprefactorsUUCG)\n",
    "\n",
    "weightsGACC=np.exp(bussilab.wham.wham(np.matmul(trajGACC,np.transpose(FFprefactorsGACC-FFprefactorsGAGA[1])),threshold=1e-20,T=kBT).logW)\n",
    "weightsGAGA=np.exp(bussilab.wham.wham(biasGAGA,threshold=1e-20,T=kBT).logW)\n",
    "weightsUUCG=np.exp(bussilab.wham.wham(biasUUCG,threshold=1e-20,T=kBT).logW)\n",
    "\n",
    "nblocks=5\n",
    "#split the trajectories into nblocks\n",
    "weightsGACC_blocks=np.array_split(weightsGACC,nblocks) \n",
    "trajGACC_blocks=np.array_split(trajGACC,nblocks) \n",
    "noe_blocks=np.array_split(noe,nblocks)\n",
    "unoe_blocks=np.array_split(unoe,nblocks)\n",
    "backbone1_blocks=np.array_split(backbone1,nblocks)\n",
    "backbone2_blocks=np.array_split(backbone2,nblocks)\n",
    "sugar_blocks=np.array_split(sugar,nblocks)\n",
    "\n",
    "weightsGAGA_blocks=np.array_split(weightsGAGA,nblocks) \n",
    "trajGAGA_blocks=np.array_split(trajGAGA,nblocks) \n",
    "populationGAGA_blocks=np.array_split(populationGAGA,nblocks)\n",
    "biasGAGA_blocks=np.array_split(biasGAGA,nblocks)\n",
    "\n",
    "weightsUUCG_blocks=np.array_split(weightsUUCG,nblocks) \n",
    "trajUUCG_blocks=np.array_split(trajUUCG,nblocks)   \n",
    "populationUUCG_blocks=np.array_split(populationUUCG,nblocks)\n",
    "biasUUCG_blocks=np.array_split(biasUUCG,nblocks)\n",
    "\n",
    "\n",
    "np.save('./data_loaded/weightsGACC_blocks.npy',weightsGACC_blocks)\n",
    "np.save('./data_loaded/trajGACC_blocks.npy',trajGACC_blocks)\n",
    "np.save('./data_loaded/noe_blocks.npy',noe_blocks)\n",
    "np.save('./data_loaded/unoe_blocks.npy',unoe_blocks)\n",
    "np.save('./data_loaded/backbone1_blocks.npy',backbone1_blocks)\n",
    "np.save('./data_loaded/backbone2_blocks.npy',backbone2_blocks)\n",
    "np.save('./data_loaded/sugar_blocks.npy',sugar_blocks)\n",
    "\n",
    "np.save('./data_loaded/weightsGAGA_blocks.npy',weightsGAGA_blocks)\n",
    "np.save('./data_loaded/trajGAGA_blocks.npy',trajGAGA_blocks)\n",
    "np.save('./data_loaded/populationGAGA_blocks.npy',populationGAGA_blocks)\n",
    "np.save('./data_loaded/biasGAGA_blocks.npy',biasGAGA_blocks)\n",
    "\n",
    "np.save('./data_loaded/weightsUUCG_blocks.npy',weightsUUCG_blocks)\n",
    "np.save('./data_loaded/trajUUCG_blocks.npy',trajUUCG_blocks)\n",
    "np.save('./data_loaded/populationUUCG_blocks.npy',populationUUCG_blocks)\n",
    "np.save('./data_loaded/biasUUCG_blocks.npy',biasUUCG_blocks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
